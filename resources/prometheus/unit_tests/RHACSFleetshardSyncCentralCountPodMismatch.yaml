rule_files:
  - /tmp/prometheus-rules-test.yaml

evaluation_interval: 1m

tests:
  # Test new instance created but pod doesn't exist
  - interval: 1m
    input_series:
      - series: acs_fleetshard_total_centrals
        values: "3x5 4x25"
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-co1cgv2hofac73cvpm5g"}
        values: "1x30"
      # Count unready instances as well
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-cq1636iqbcns73fiki8g"}
        values: "0x30"
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-cr2o56pjctnc739qmqv0"}
        values: "0x5 1x25"
    alert_rule_test:
      - eval_time: 10m
        alertname: RHACSFleetshardSyncCentralCountPodMismatch
        exp_alerts: []
      - eval_time: 25m
        alertname: RHACSFleetshardSyncCentralCountPodMismatch
        exp_alerts:
          - exp_labels:
              alertname: RHACSFleetshardSyncCentralCountPodMismatch
              severity: warning
            exp_annotations:
              summary: "Fleetshard synchronizer manages 4 centrals while the central pod count is 3."
              description: "For the last 15 minutes, the number of Central returned from Fleet Manager in Fleetshard Sync is different from the number of Central pods on the cluster. This may be a sign of a reconciliation breakdown and the Central SLI metrics may not match the actual state."
              sop_url: "https://gitlab.cee.redhat.com/stackrox/acs-managed-service-runbooks/blob/master/sops/dp-007-fleetshard-sync-reconciliation-error.md"
  # Test an instance is deleted but the pod still exists
  - interval: 1m
    input_series:
      - series: acs_fleetshard_total_centrals
        values: "4x5 3x25"
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-co1cgv2hofac73cvpm5g"}
        values: "1x30"
      # Count unready instances as well
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-cq1636iqbcns73fiki8g"}
        values: "0x30"
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-cr2o56pjctnc739qmqv0"}
        values: "0x5 1x25"
      - series: kube_deployment_status_replicas_ready{deployment="central", namespace="rhacs-cu3nrb4qls9s73emtae0"}
        values: "1x30"
    alert_rule_test:
      - eval_time: 10m
        alertname: RHACSFleetshardSyncCentralCountPodMismatch
        exp_alerts: [ ]
      - eval_time: 25m
        alertname: RHACSFleetshardSyncCentralCountPodMismatch
        exp_alerts:
          - exp_labels:
              alertname: RHACSFleetshardSyncCentralCountPodMismatch
              severity: warning
            exp_annotations:
              summary: "Fleetshard synchronizer manages 3 centrals while the central pod count is 4."
              description: "For the last 15 minutes, the number of Central returned from Fleet Manager in Fleetshard Sync is different from the number of Central pods on the cluster. This may be a sign of a reconciliation breakdown and the Central SLI metrics may not match the actual state."
              sop_url: "https://gitlab.cee.redhat.com/stackrox/acs-managed-service-runbooks/blob/master/sops/dp-007-fleetshard-sync-reconciliation-error.md"
